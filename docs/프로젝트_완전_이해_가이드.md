# Loopers Kotlin Spring Template 프로젝트 완전 이해 가이드

이 문서는 이 프로젝트를 처음 접하는 사람이 프로젝트의 모든 측면을 완벽하게 이해하고, 필요하다면 처음부터 동일한 프로젝트를 구축할 수 있도록 작성되었습니다. 모든 설명은 완전한 문장으로 작성되어 있으며, 각 개념과 설계 결정의 이유를 상세하게 설명합니다.

---

## 1. 이 프로젝트가 무엇인지 이해하기

### 1.1 프로젝트의 정체성

이 프로젝트는 "loopers-kotlin-spring-template"이라는 이름을 가진 멀티모듈 Spring Boot 템플릿 프로젝트입니다. 이 프로젝트의 주된 목적은 Kotlin 언어와 Spring Boot 프레임워크를 사용하여 엔터프라이즈급 애플리케이션을 빠르게 시작할 수 있는 기반을 제공하는 것입니다. 프로젝트는 "com.loopers"라는 그룹 아이디를 사용하며, Gradle 빌드 도구를 Kotlin DSL로 설정하여 타입 안전성을 확보하고 있습니다.

이 템플릿은 단순히 코드를 모아놓은 것이 아니라, 실제 운영 환경에서 사용할 수 있도록 다양한 인프라 컴포넌트(데이터베이스, 캐시, 메시징)와 모니터링 도구를 통합하고 있습니다. 또한 코드 품질을 유지하기 위한 자동화된 린팅과 테스트 인프라를 갖추고 있어, 새로운 팀원이 합류하더라도 일관된 코드 스타일과 품질을 유지할 수 있습니다.

### 1.2 왜 Kotlin과 Java 21을 선택했는가

이 프로젝트는 Kotlin 2.0.20 버전과 Java 21을 사용합니다. Kotlin을 선택한 이유는 Java보다 간결하면서도 null 안전성을 언어 차원에서 제공하기 때문입니다. Spring Framework는 원래 Java 기반으로 설계되었지만, Kotlin은 Java와 완벽하게 상호 운용이 가능하면서도 더 현대적인 언어 기능을 제공합니다. 예를 들어, Kotlin의 data class는 equals, hashCode, toString을 자동으로 생성해주며, null 안전성은 NullPointerException을 컴파일 시점에 방지할 수 있게 해줍니다.

Java 21을 선택한 이유는 이것이 LTS(Long Term Support) 버전이기 때문입니다. Java 21은 Virtual Threads, Pattern Matching, Record Patterns 같은 현대적인 기능을 제공하면서도 장기간 지원이 보장됩니다. 이는 프로덕션 환경에서 안정성과 성능을 모두 확보할 수 있다는 의미입니다.

### 1.3 Spring Boot 3.4.4를 사용하는 이유

프로젝트는 Spring Boot 3.4.4 버전을 사용합니다. Spring Boot 3.x 버전은 Java 17 이상을 요구하며, Jakarta EE를 기반으로 합니다. 이는 과거 Java EE(javax 패키지)에서 Jakarta EE(jakarta 패키지)로의 전환을 의미하며, 이 프로젝트의 모든 코드에서 `jakarta.persistence.*` 같은 패키지를 사용하는 이유입니다. Spring Boot 3.x는 또한 GraalVM Native Image 지원, 향상된 관찰성(Observability), 그리고 성능 개선을 제공합니다.

### 1.4 프로젝트가 해결하려는 문제

많은 개발 팀이 새로운 프로젝트를 시작할 때 반복적으로 마주치는 문제들이 있습니다. 데이터베이스 연결 설정, 캐시 구성, 메시징 시스템 통합, 로깅 설정, 모니터링 도구 연동 등입니다. 이 템플릿은 이러한 반복적인 설정을 미리 구성해두어, 개발자가 비즈니스 로직에만 집중할 수 있게 합니다.

또한 이 프로젝트는 "어떻게 코드를 구조화할 것인가"라는 아키텍처적 질문에 대한 답을 제시합니다. 계층화된 아키텍처(Layered Architecture)와 3-Tier 모듈 구조를 통해, 코드를 어디에 작성해야 하는지, 어떤 모듈이 어떤 책임을 가져야 하는지를 명확하게 정의합니다.

---

## 2. 프로젝트의 핵심 아키텍처 이해하기

### 2.1 3-Tier 모듈 구조의 철학

이 프로젝트는 세 개의 계층으로 모듈을 구분합니다: `apps`, `modules`, `supports`. 이러한 구분은 단순히 폴더를 나누는 것이 아니라, 각 모듈의 책임과 재사용성에 대한 명확한 원칙을 제시합니다.

#### 첫 번째 계층: apps - 실행 가능한 애플리케이션

`apps` 디렉토리에 있는 모듈들은 실제로 실행할 수 있는 Spring Boot 애플리케이션입니다. 각 모듈은 `@SpringBootApplication` 애노테이션이 붙은 메인 클래스를 가지고 있으며, 독립적으로 실행될 수 있습니다. 이 프로젝트에는 세 개의 애플리케이션이 있습니다:

**commerce-api**는 REST API를 제공하는 웹 서버입니다. 이 애플리케이션은 HTTP 요청을 받아서 비즈니스 로직을 처리하고 응답을 반환합니다. 예를 들어, 상품 목록을 조회하거나, 주문을 생성하는 API를 제공합니다. 이 애플리케이션은 Tomcat 같은 서블릿 컨테이너를 내장하고 있어, 별도의 웹 서버 없이 단독으로 실행될 수 있습니다.

**commerce-batch**는 배치 처리를 담당하는 애플리케이션입니다. 배치 처리란 대량의 데이터를 주기적으로 처리하는 작업을 의미합니다. 예를 들어, 매일 밤 12시에 그날의 주문을 집계하거나, 만료된 쿠폰을 정리하는 작업을 수행할 수 있습니다. 이 애플리케이션은 웹 서버를 포함하지 않으며, 스케줄러에 의해 주기적으로 실행되거나 수동으로 실행됩니다.

**commerce-streamer**는 실시간 이벤트 스트림을 처리하는 애플리케이션입니다. Kafka 같은 메시지 브로커에서 이벤트를 소비하여 처리합니다. 예를 들어, 주문이 생성될 때마다 발행되는 이벤트를 받아서 재고를 업데이트하거나, 사용자에게 알림을 보내는 작업을 수행할 수 있습니다. 이 애플리케이션도 웹 서버 없이 독립적으로 실행됩니다.

이 세 애플리케이션은 각각 다른 목적을 가지고 있지만, 동일한 도메인(커머스)을 다룹니다. 따라서 공통된 데이터베이스 구조나 비즈니스 로직을 공유할 수 있습니다. 이러한 공유는 `modules`와 `supports` 계층을 통해 이루어집니다.

Gradle 빌드 설정에서 `apps` 디렉토리의 모듈들은 특별하게 취급됩니다. 이들은 BootJar를 생성하도록 설정되어 있는데, BootJar란 모든 의존성을 포함한 실행 가능한 JAR 파일을 의미합니다. 일반적인 JAR 파일은 라이브러리로 사용되지만, BootJar는 `java -jar` 명령어로 직접 실행할 수 있습니다.

#### 두 번째 계층: modules - 재사용 가능한 인프라 설정

`modules` 디렉토리에 있는 모듈들은 기술적인 인프라 설정을 담당합니다. 이들은 특정 비즈니스 도메인에 종속되지 않으며, 다른 프로젝트에서도 그대로 가져다 사용할 수 있도록 설계되었습니다. 이 원칙은 매우 중요합니다 - `modules`에는 "주문"이나 "상품" 같은 도메인 개념이 들어가서는 안 되며, 오직 "JPA를 어떻게 설정할 것인가", "Redis를 어떻게 사용할 것인가" 같은 기술적인 내용만 포함됩니다.

**jpa 모듈**은 데이터베이스 접근을 위한 JPA/Hibernate 설정을 제공합니다. 이 모듈에는 HikariCP 데이터베이스 커넥션 풀 설정, QueryDSL 설정, 그리고 모든 엔티티가 상속받을 수 있는 BaseEntity 클래스가 포함되어 있습니다. BaseEntity는 id, createdAt, updatedAt, deletedAt 같은 모든 엔티티가 공통으로 가져야 하는 필드를 정의합니다. 이 모듈은 또한 `java-test-fixtures` 플러그인을 사용하여 테스트용 유틸리티를 제공합니다. DatabaseCleanUp 클래스는 테스트 후 데이터베이스를 깨끗하게 정리하며, MySqlTestContainersConfig는 실제 MySQL 컨테이너를 사용한 통합 테스트를 가능하게 합니다.

**redis 모듈**은 Redis 캐시 설정을 제공합니다. 단순히 Redis에 연결하는 것을 넘어, Master-Replica 구조를 지원합니다. Master는 쓰기와 읽기를 모두 처리할 수 있지만, Replica는 읽기만 가능합니다. 이 모듈은 두 개의 RedisTemplate을 제공합니다 - 기본 템플릿은 읽기를 Replica에 우선 분배하여 Master의 부하를 줄이고, Master 템플릿은 항상 Master에서 읽고 써서 강한 일관성을 보장합니다. 개발자는 상황에 따라 적절한 템플릿을 선택할 수 있습니다.

**kafka 모듈**은 Apache Kafka 메시징 시스템 설정을 제공합니다. Producer와 Consumer 설정이 모두 포함되어 있으며, JSON 직렬화를 사용합니다. 중요한 점은 Consumer가 수동 커밋 모드로 설정되어 있다는 것입니다. 자동 커밋은 편리하지만, 메시지 처리 중 오류가 발생해도 오프셋이 커밋되어 메시지를 잃어버릴 수 있습니다. 수동 커밋은 개발자가 명시적으로 처리 완료를 표시해야 하므로, 메시지 손실을 방지할 수 있습니다.

이 모듈들은 일반 JAR 파일로 빌드되며, BootJar는 생성하지 않습니다. 왜냐하면 이들은 독립적으로 실행되는 것이 아니라, `apps`의 애플리케이션들에 의해 라이브러리로 사용되기 때문입니다.

#### 세 번째 계층: supports - 부가 기능 유틸리티

`supports` 디렉토리에 있는 모듈들은 횡단 관심사(Cross-cutting Concerns)를 다룹니다. 횡단 관심사란 애플리케이션의 여러 계층에 걸쳐 공통으로 필요한 기능을 의미합니다. 로깅, 모니터링, JSON 직렬화 같은 것들이 이에 해당합니다.

**jackson 모듈**은 JSON 직렬화/역직렬화를 커스터마이징합니다. Spring Boot는 기본적으로 Jackson 라이브러리를 사용하지만, 때로는 날짜 포맷을 변경하거나, null 값을 어떻게 처리할지 등을 조정해야 합니다. 이 모듈은 ObjectMapper를 커스터마이징하여 프로젝트 전체에서 일관된 JSON 처리 방식을 보장합니다.

**logging 모듈**은 로깅 설정을 중앙화합니다. Logback 설정 파일의 위치를 지정하며, Slack Appender 같은 커스텀 Appender를 설정할 수 있습니다. Slack Appender는 에러 로그를 Slack 채널로 전송하여, 개발자가 즉시 문제를 인지할 수 있게 합니다.

**monitoring 모듈**은 Spring Boot Actuator와 Prometheus 메트릭을 설정합니다. Actuator는 애플리케이션의 헬스 체크, 메트릭, 환경 정보 등을 HTTP 엔드포인트로 노출합니다. Prometheus는 이 메트릭을 주기적으로 수집하여 시계열 데이터베이스에 저장하고, Grafana는 이를 시각화합니다. 개발자는 대시보드를 통해 JVM 메모리 사용량, API 응답 시간, 에러율 등을 실시간으로 모니터링할 수 있습니다.

### 2.2 애플리케이션 내부의 계층 구조

`apps` 디렉토리의 각 애플리케이션 내부는 Layered Architecture(계층화된 아키텍처)를 따릅니다. 이는 코드를 책임에 따라 여러 계층으로 나누는 패턴입니다. 각 계층은 명확한 역할을 가지며, 의존성은 한 방향으로만 흐릅니다.

#### interfaces 계층 - 외부와의 경계

가장 바깥쪽 계층은 `interfaces`입니다. 이 계층은 외부 세계(HTTP 클라이언트, 다른 시스템)와 애플리케이션 사이의 경계를 정의합니다. REST API의 경우, 컨트롤러가 이 계층에 위치합니다.

예를 들어, `ExampleV1Controller`를 살펴보겠습니다. 이 컨트롤러는 `/api/v1/examples/{exampleId}` 경로로 들어오는 GET 요청을 처리합니다. 중요한 점은 컨트롤러가 직접 비즈니스 로직을 처리하지 않는다는 것입니다. 대신, `ExampleFacade`를 호출하여 처리를 위임합니다. 컨트롤러의 책임은 오직 HTTP 요청을 받아서 적절한 서비스를 호출하고, 결과를 HTTP 응답으로 변환하는 것입니다.

이 계층에는 DTO(Data Transfer Object)도 포함됩니다. `ExampleV1Dto.ExampleResponse`는 API 응답의 구조를 정의합니다. DTO는 도메인 모델과는 다릅니다. 도메인 모델은 비즈니스 로직과 규칙을 담고 있지만, DTO는 단순히 데이터를 전달하는 역할만 합니다. 이러한 분리는 중요합니다 - API 응답 구조를 변경해도 도메인 로직에 영향을 주지 않으며, 반대로 도메인 로직을 변경해도 API 계약을 유지할 수 있습니다.

또한 `ApiControllerAdvice`라는 전역 예외 처리기가 있습니다. 애플리케이션 어디서든 `CoreException`이 발생하면, 이 클래스가 이를 캐치하여 적절한 HTTP 상태 코드와 에러 메시지로 변환합니다. 이를 통해 일관된 에러 응답 형식을 유지할 수 있습니다.

#### application 계층 - 유스케이스 조율

`application` 계층은 애플리케이션의 유스케이스를 조율합니다. 유스케이스란 "사용자가 시스템을 통해 달성하려는 목표"를 의미합니다. 예를 들어, "예시를 조회한다"는 하나의 유스케이스입니다.

`ExampleFacade` 클래스를 보면, `getExample` 메서드가 있습니다. 이 메서드는 `ExampleService`를 호출하여 도메인 모델을 가져온 후, 이를 `ExampleInfo`로 변환합니다. 왜 이런 변환이 필요할까요? 도메인 모델(`ExampleModel`)은 JPA 엔티티이며, 많은 메타데이터와 프록시 객체를 포함할 수 있습니다. 이를 그대로 반환하면 의도하지 않은 지연 로딩이나 순환 참조 문제가 발생할 수 있습니다. `ExampleInfo`는 순수한 데이터 클래스로, 필요한 정보만 담고 있어 안전합니다.

더 복잡한 유스케이스의 경우, Facade는 여러 도메인 서비스를 조율할 수 있습니다. 예를 들어, "주문 생성" 유스케이스는 사용자 정보 확인, 상품 재고 확인, 주문 생성, 재고 차감, 포인트 적립 등 여러 단계를 포함할 수 있습니다. Facade는 이러한 단계들을 올바른 순서로 실행하고, 트랜잭션 경계를 관리합니다.

#### domain 계층 - 핵심 비즈니스 로직

`domain` 계층은 애플리케이션의 핵심입니다. 이 계층에는 비즈니스 규칙과 로직이 담겨 있습니다. 도메인 모델, 도메인 서비스, 리포지토리 인터페이스가 여기에 위치합니다.

`ExampleModel`을 자세히 살펴보겠습니다. 이 클래스는 단순한 데이터 컨테이너가 아닙니다. `init` 블록에서 생성 시점의 불변식(invariant)을 검증합니다. 이름이나 설명이 비어있으면 객체 생성을 거부합니다. 이는 "유효하지 않은 상태의 객체는 존재할 수 없다"는 원칙을 구현합니다.

또한 `name`과 `description` 필드는 `protected set`으로 선언되어 있습니다. 이는 외부에서 직접 수정할 수 없고, `update` 같은 메서드를 통해서만 변경할 수 있다는 의미입니다. `update` 메서드는 변경 전에 검증을 수행합니다. 이러한 패턴을 "Rich Domain Model"이라고 부릅니다 - 데이터뿐만 아니라 행동(behavior)도 포함하는 도메인 모델입니다.

`ExampleService`는 도메인 서비스입니다. 도메인 서비스는 여러 엔티티를 조율하거나, 단일 엔티티로 표현하기 어려운 비즈니스 로직을 담습니다. 예를 들어, "특정 예시 조회"는 간단해 보이지만, 실제로는 "예시가 존재하지 않으면 예외를 발생시킨다"는 비즈니스 규칙을 포함합니다. 이 서비스는 `@Transactional(readOnly = true)`로 선언되어 있어, 읽기 전용 트랜잭션을 사용합니다. 읽기 전용 트랜잭션은 데이터베이스에 불필요한 쓰기 잠금을 걸지 않아 성능이 더 좋습니다.

`ExampleRepository` 인터페이스도 중요합니다. 이 인터페이스는 도메인 계층에 있지만, 구현체는 infrastructure 계층에 있습니다. 이는 의존성 역전 원칙(Dependency Inversion Principle)의 적용입니다. 도메인 계층은 인프라 계층에 의존하지 않고, 오히려 인프라 계층이 도메인 계층이 정의한 인터페이스를 구현합니다. 이를 통해 도메인 로직을 데이터베이스 기술로부터 독립적으로 유지할 수 있습니다.

#### infrastructure 계층 - 외부 시스템 연동

`infrastructure` 계층은 외부 시스템과의 실제 통신을 담당합니다. 데이터베이스, 외부 API, 파일 시스템 등 모든 I/O 작업이 여기서 이루어집니다.

`ExampleRepositoryImpl`은 도메인 계층의 `ExampleRepository` 인터페이스를 구현합니다. 이 클래스는 `ExampleJpaRepository`(Spring Data JPA의 JpaRepository를 상속한 인터페이스)를 사용하여 실제 데이터베이스 작업을 수행합니다. 중요한 점은 JPA의 세부사항이 이 계층에 감춰져 있다는 것입니다. 도메인 계층은 "id로 예시를 찾아라"라는 추상적인 명령만 내릴 뿐, 그것이 SQL로 어떻게 변환되는지는 알지 못합니다.

만약 나중에 JPA 대신 MyBatis를 사용하기로 결정한다면, `ExampleRepositoryImpl`만 새로 작성하면 됩니다. 도메인 계층의 코드는 전혀 변경할 필요가 없습니다. 이것이 계층 분리의 힘입니다.

#### support 계층 - 애플리케이션별 지원 기능

`support` 계층에는 이 애플리케이션에 특화된 유틸리티가 위치합니다. `supports` 모듈과는 다릅니다 - `supports`는 모든 애플리케이션에서 재사용할 수 있는 범용 기능이지만, `support`는 이 애플리케이션만의 특별한 필요를 충족합니다.

예를 들어, `ErrorType` 열거형은 이 애플리케이션에서 발생할 수 있는 에러 타입을 정의합니다. `CoreException`은 이러한 에러 타입을 사용하는 커스텀 예외입니다. 도메인 계층에서 비즈니스 규칙 위반이 발생하면 이 예외를 던지고, `ApiControllerAdvice`가 이를 적절한 HTTP 응답으로 변환합니다.

### 2.3 의존성의 방향

이러한 계층 구조에서 가장 중요한 원칙은 의존성의 방향입니다. interfaces는 application에 의존하고, application은 domain에 의존하며, domain은 아무에게도 의존하지 않습니다. infrastructure는 domain이 정의한 인터페이스를 구현합니다.

이 원칙을 지키면 여러 가지 이점이 있습니다. 첫째, 도메인 로직을 테스트하기 쉽습니다. 데이터베이스나 외부 API 없이도 도메인 로직만 따로 테스트할 수 있습니다. 둘째, 기술 스택을 쉽게 교체할 수 있습니다. 셋째, 비즈니스 로직이 기술 세부사항에 오염되지 않습니다.

---

## 3. 빌드 시스템 완전히 이해하기

### 3.1 Gradle을 선택한 이유

이 프로젝트는 Gradle을 빌드 도구로 사용합니다. Maven도 널리 사용되는 빌드 도구이지만, Gradle은 몇 가지 장점이 있습니다. 첫째, Gradle은 프로그래밍 언어(Groovy 또는 Kotlin)로 빌드 스크립트를 작성할 수 있어 더 유연합니다. 둘째, 증분 빌드(Incremental Build)를 지원하여 변경된 부분만 다시 빌드하므로 빌드 속도가 빠릅니다. 셋째, 멀티모듈 프로젝트를 더 직관적으로 관리할 수 있습니다.

이 프로젝트는 Gradle의 Kotlin DSL을 사용합니다. Groovy DSL도 가능하지만, Kotlin DSL은 타입 안전성과 IDE 자동완성을 제공합니다. 빌드 스크립트에서 오타를 내면 컴파일 에러가 발생하므로, 런타임에 빌드가 실패하는 것을 방지할 수 있습니다.

### 3.2 Gradle Wrapper의 중요성

프로젝트 루트에 `gradlew`(Linux/Mac)와 `gradlew.bat`(Windows) 파일이 있습니다. 이들은 Gradle Wrapper 스크립트입니다. Gradle Wrapper를 사용하면 개발자가 직접 Gradle을 설치하지 않아도 됩니다. Wrapper 스크립트를 실행하면 자동으로 올바른 버전의 Gradle을 다운로드하여 사용합니다.

이것이 왜 중요할까요? 개발팀의 각 개발자가 서로 다른 Gradle 버전을 사용한다면, 어떤 개발자의 환경에서는 빌드가 성공하지만 다른 개발자의 환경에서는 실패할 수 있습니다. Gradle Wrapper를 사용하면 모든 개발자와 CI/CD 환경이 정확히 동일한 Gradle 버전을 사용하게 되어, "내 컴퓨터에서는 되는데요" 같은 문제를 방지할 수 있습니다.

`gradle/wrapper/gradle-wrapper.properties` 파일에 Gradle 버전이 명시되어 있습니다. 이 버전을 변경하면 모든 개발자가 자동으로 새 버전을 사용하게 됩니다.

### 3.3 settings.gradle.kts의 역할

`settings.gradle.kts` 파일은 Gradle 프로젝트의 설정을 정의합니다. 가장 먼저 `rootProject.name = "loopers-kotlin-spring-template"`로 프로젝트 이름을 설정합니다.

그 다음, `include` 블록에서 이 프로젝트에 포함된 모든 모듈을 선언합니다. Gradle은 이 선언을 보고 각 모듈을 인식합니다. 모듈 이름은 계층적 구조를 가집니다 - `:apps:commerce-api`는 `apps` 디렉토리 아래 `commerce-api` 모듈을 의미합니다.

`pluginManagement` 블록은 플러그인 관리를 설정합니다. Gradle 플러그인은 빌드에 추가 기능을 제공합니다. 예를 들어, `org.jetbrains.kotlin.jvm` 플러그인은 Kotlin 코드를 컴파일하는 기능을 추가합니다. 이 블록에서는 플러그인을 어디서 다운로드할지(repositories), 어떤 버전을 사용할지(resolutionStrategy)를 정의합니다.

중요한 점은 버전이 `gradle.properties` 파일에서 주입된다는 것입니다. `val kotlinVersion: String by settings`는 `gradle.properties`의 `kotlinVersion` 속성을 읽어옵니다. 이렇게 하면 버전 정보를 한 곳에서 관리할 수 있습니다. Kotlin 버전을 업그레이드하려면 `gradle.properties` 파일의 한 줄만 수정하면 됩니다.

### 3.4 루트 build.gradle.kts 파일 상세 분석

루트 `build.gradle.kts` 파일은 모든 서브모듈에 공통으로 적용되는 설정을 정의합니다. 이 파일을 이해하면 프로젝트의 빌드 구조를 완전히 이해할 수 있습니다.

#### getGitHash 함수

파일 상단에 `getGitHash` 함수가 있습니다. 이 함수는 현재 Git 커밋의 짧은 해시값을 반환합니다. `providers.exec`를 사용하여 `git rev-parse --short HEAD` 명령어를 실행하고, 그 출력을 읽어옵니다. 만약 Git이 설치되어 있지 않거나 Git 저장소가 아니라면, `runCatching` 블록의 `getOrElse`에 의해 "init"을 반환합니다.

왜 Git 해시를 가져올까요? 프로젝트 버전으로 사용하기 위해서입니다. 나중에 `allprojects` 블록에서 `version = if (version == DEFAULT_VERSION) getGitHash() else version`라는 코드가 있습니다. 이는 "명시적으로 버전을 지정하지 않았다면 Git 커밋 해시를 버전으로 사용하라"는 의미입니다. 이렇게 하면 빌드된 JAR 파일의 이름이 `commerce-api-abc123.jar` 같은 형태가 되어, 어떤 커밋에서 빌드되었는지 추적할 수 있습니다.

#### 플러그인 적용

`plugins` 블록에서 루트 프로젝트에 적용할 플러그인을 선언합니다. 주목할 점은 일부 플러그인에 `apply false`가 붙어있다는 것입니다. 이는 "이 플러그인을 루트 프로젝트에는 적용하지 말고, 서브모듈에서 필요할 때 적용하라"는 의미입니다. 루트 프로젝트는 실제 코드를 컴파일하지 않으므로 Kotlin 플러그인이 필요 없습니다.

`id("io.spring.dependency-management")`는 Spring의 의존성 관리 플러그인입니다. 이 플러그인은 Spring Boot BOM(Bill of Materials)을 사용하여 라이브러리 버전을 일관되게 관리합니다. 예를 들어, `spring-boot-starter-web`을 의존성으로 추가할 때 버전을 명시하지 않아도, BOM에 정의된 호환되는 버전을 자동으로 사용합니다.

#### Java 및 Kotlin 컴파일러 설정

`java` 블록에서 Java 툴체인을 설정합니다. `languageVersion = JavaLanguageVersion.of(21)`은 Java 21을 사용하라는 의미입니다. Gradle은 시스템에 Java 21이 설치되어 있지 않으면 자동으로 다운로드할 수도 있습니다(툴체인 자동 프로비저닝).

`kotlin` 블록에서는 Kotlin 컴파일러 옵션을 설정합니다. `jvmToolchain(21)`은 Kotlin 코드를 Java 21 바이트코드로 컴파일하라는 의미입니다. `freeCompilerArgs.addAll("-Xjsr305=strict")`는 JSR-305 애노테이션(@Nullable, @Nonnull 등)을 엄격하게 처리하라는 옵션입니다. 이는 Kotlin의 null 안전성을 Java 라이브러리와 함께 사용할 때 더 강력하게 만듭니다.

#### allprojects 블록

`allprojects` 블록은 루트 프로젝트와 모든 서브모듈에 적용되는 설정입니다. 여기서는 그룹 ID와 버전을 설정하고, Maven Central 저장소를 추가합니다. Maven Central은 대부분의 Java/Kotlin 라이브러리가 호스팅되는 중앙 저장소입니다.

#### subprojects 블록 - 핵심 설정

`subprojects` 블록이 가장 중요합니다. 이 블록의 모든 설정은 서브모듈(apps, modules, supports의 모든 모듈)에 적용됩니다.

먼저 모든 서브모듈에 필요한 플러그인을 적용합니다. `apply(plugin = "org.jetbrains.kotlin.jvm")`은 Kotlin 코드를 컴파일할 수 있게 하고, `apply(plugin = "org.jetbrains.kotlin.kapt")`는 Kotlin Annotation Processing을 활성화합니다. kapt는 QueryDSL이나 JPA 같은 애노테이션 프로세서를 Kotlin에서 사용할 수 있게 해줍니다.

`apply(plugin = "org.jetbrains.kotlin.plugin.spring")`은 Spring과 Kotlin을 함께 사용할 때 필요한 플러그인입니다. Spring의 많은 클래스는 상속이나 오버라이딩을 위해 `open` 키워드가 필요한데, 이 플러그인은 `@Configuration`, `@Service` 같은 Spring 애노테이션이 붙은 클래스를 자동으로 `open`으로 만들어줍니다.

`apply(plugin = "jacoco")`는 코드 커버리지 측정 도구입니다. 테스트가 얼마나 많은 코드를 실행했는지 측정하여, 테스트가 부족한 부분을 찾을 수 있습니다.

`apply(plugin = "org.jlleitschuh.gradle.ktlint")`는 Kotlin 코드 스타일 검사 도구입니다. 코드 포맷이 일관되지 않으면 가독성이 떨어지고, 코드 리뷰 시 본질적인 변경과 포맷 변경을 구분하기 어렵습니다. ktlint는 자동으로 코드 스타일을 검사하고 수정할 수 있습니다.

#### dependencyManagement 블록

`dependencyManagement` 블록에서 Spring Cloud BOM을 임포트합니다. BOM(Bill of Materials)은 서로 호환되는 라이브러리 버전들의 집합입니다. Spring Cloud는 많은 컴포넌트로 구성되어 있는데, 각 컴포넌트의 버전을 개별적으로 관리하면 호환성 문제가 발생할 수 있습니다. BOM을 사용하면 하나의 버전(여기서는 2024.0.1)만 지정하면 모든 컴포넌트의 호환되는 버전이 자동으로 결정됩니다.

#### dependencies 블록 - 공통 의존성

`dependencies` 블록에서 모든 서브모듈이 공통으로 필요로 하는 라이브러리를 선언합니다. 이렇게 하면 각 모듈의 `build.gradle.kts`에서 반복적으로 선언하지 않아도 됩니다.

Kotlin 관련 의존성으로는 `kotlin-reflect`와 `kotlin-stdlib-jdk8`이 있습니다. kotlin-reflect는 리플렉션 기능을 제공하며, Spring은 내부적으로 리플렉션을 많이 사용하므로 필수입니다.

Spring 관련으로는 `spring-boot-starter`가 기본적으로 포함됩니다. 이는 모든 Spring Boot 애플리케이션의 기본 의존성입니다. `spring-boot-starter-validation`은 Bean Validation(JSR-303)을 제공하여, DTO 검증 등에 사용할 수 있습니다.

Jackson 관련 의존성도 포함됩니다. `jackson-module-kotlin`은 Kotlin 클래스를 JSON으로 직렬화/역직렬화할 수 있게 해주고, `jackson-datatype-jsr310`은 Java 8의 날짜/시간 API(LocalDateTime 등)를 지원합니다.

테스트 관련 의존성은 `testImplementation`으로 선언되어, 테스트 코드에서만 사용됩니다. `spring-boot-starter-test`는 JUnit, Mockito, AssertJ 등 테스트에 필요한 대부분의 라이브러리를 포함합니다. `springmockk`는 Kotlin에서 Mockito보다 편리하게 모킹을 할 수 있게 해줍니다. `instancio-junit`은 테스트 데이터를 쉽게 생성할 수 있는 라이브러리입니다.

Testcontainers 의존성도 포함됩니다. Testcontainers는 Docker 컨테이너를 사용하여 실제 데이터베이스, Redis 등을 테스트 환경에서 실행할 수 있게 해줍니다. 이는 인메모리 데이터베이스를 사용하는 것보다 프로덕션 환경과 가까운 테스트를 가능하게 합니다.

#### Jar와 BootJar 설정

기본적으로 모든 모듈은 일반 JAR를 생성하고 BootJar는 생성하지 않습니다(`tasks.withType(Jar::class) { enabled = true }` 및 `tasks.withType(BootJar::class) { enabled = false }`). 일반 JAR는 라이브러리로 사용될 수 있지만, 단독으로 실행할 수는 없습니다.

하지만 `apps` 디렉토리의 모듈들은 예외입니다. `configure(allprojects.filter { it.parent?.name.equals("apps") })` 블록에서 이들은 일반 JAR를 생성하지 않고 BootJar만 생성합니다. BootJar는 모든 의존성을 포함한 "fat jar"로, `java -jar` 명령으로 실행할 수 있습니다.

#### 테스트 설정

`tasks.test` 블록은 테스트 실행 방식을 설정합니다. `maxParallelForks = 1`은 테스트를 병렬로 실행하지 않고 순차적으로 실행하라는 의미입니다. Testcontainers를 사용할 때 병렬 실행은 때때로 포트 충돌 등의 문제를 일으킬 수 있습니다.

`useJUnitPlatform()`은 JUnit 5를 사용하라는 선언입니다. JUnit 4와 JUnit 5는 다른 플랫폼을 사용하므로, 명시적으로 지정해야 합니다.

`systemProperty("user.timezone", "Asia/Seoul")`은 모든 테스트를 서울 시간대로 실행합니다. 날짜/시간 관련 테스트가 실행 환경에 따라 다른 결과를 내는 것을 방지합니다.

`systemProperty("spring.profiles.active", "test")`는 테스트 실행 시 `test` 프로파일을 활성화합니다. 이를 통해 `application.yml`의 `---` 구분자 아래에 있는 test 프로파일 설정을 사용할 수 있습니다.

#### JaCoCo 설정

`tasks.withType<JacocoReport>` 블록은 코드 커버리지 리포트 생성을 설정합니다. `xml.required = true`는 XML 형식의 리포트를 생성하라는 의미입니다. XML 리포트는 CI/CD 도구나 코드 분석 도구에서 읽을 수 있습니다. HTML과 CSV 리포트는 비활성화되어 있어, 빌드 속도를 높입니다.

#### ktlint 설정

`configure<org.jlleitschuh.gradle.ktlint.KtlintExtension>` 블록은 ktlint 버전을 설정합니다. 버전은 역시 `gradle.properties`에서 읽어옵니다.

#### 모듈 컨테이너 비활성화

마지막으로, `apps`, `modules`, `supports` 디렉토리 자체의 모든 Task를 비활성화합니다. 이들은 실제 모듈이 아니라 모듈을 담는 컨테이너일 뿐이므로, 빌드할 필요가 없습니다.

### 3.5 개별 모듈의 build.gradle.kts

각 모듈은 자신의 `build.gradle.kts` 파일을 가집니다. 루트 `build.gradle.kts`에서 공통 설정을 제공하므로, 모듈별 파일은 매우 간결합니다.

예를 들어, `apps/commerce-api/build.gradle.kts`를 보면, 먼저 JPA 플러그인을 적용합니다. 이는 JPA 엔티티 클래스에 no-arg 생성자를 자동으로 추가해줍니다. JPA는 리플렉션을 사용하여 엔티티를 인스턴스화하는데, 이를 위해 기본 생성자가 필요합니다. Kotlin은 기본적으로 모든 생성자 파라미터가 있는 생성자만 만들지만, 이 플러그인이 자동으로 기본 생성자를 추가해줍니다.

의존성 섹션에서는 프로젝트 내부 모듈을 참조합니다. `implementation(project(":modules:jpa"))`는 jpa 모듈에 의존한다는 의미입니다. 이렇게 하면 jpa 모듈이 제공하는 모든 클래스와 설정을 사용할 수 있습니다.

외부 라이브러리도 추가합니다. `spring-boot-starter-web`은 웹 애플리케이션에 필요한 모든 것(Tomcat, Spring MVC 등)을 포함합니다. `springdoc-openapi-starter-webmvc-ui`는 Swagger UI를 제공하여, API 문서를 자동으로 생성하고 브라우저에서 테스트할 수 있게 해줍니다.

`kapt("com.querydsl:querydsl-apt::jakarta")`는 QueryDSL의 Q클래스를 생성합니다. QueryDSL은 타입 안전한 쿼리를 작성할 수 있게 해주는데, 각 엔티티에 대해 Q클래스(예: QExampleModel)를 생성합니다. kapt는 컴파일 시점에 이 클래스들을 자동으로 생성합니다.

`testImplementation(testFixtures(project(":modules:jpa")))`는 jpa 모듈의 testFixtures를 사용합니다. testFixtures는 테스트용 유틸리티 클래스를 다른 모듈과 공유할 수 있게 하는 Gradle 기능입니다.

---

## 4. 인프라 환경 완전히 이해하기

### 4.1 왜 Docker Compose를 사용하는가

개발 환경을 구축할 때 가장 큰 어려움은 "내 컴퓨터에서는 되는데"라는 문제입니다. 한 개발자는 MySQL 8.0을 사용하고 다른 개발자는 MySQL 5.7을 사용한다면, 같은 코드가 다르게 동작할 수 있습니다. Docker Compose는 이 문제를 해결합니다.

Docker Compose는 여러 Docker 컨테이너를 하나의 YAML 파일로 정의하고 관리할 수 있게 해줍니다. 모든 개발자가 동일한 `docker-compose.yml` 파일을 사용하면, 모두 정확히 같은 버전의 MySQL, Redis, Kafka를 사용하게 됩니다. 컨테이너는 격리되어 있어서, 시스템에 직접 설치하지 않아도 되고, 필요 없을 때는 쉽게 삭제할 수 있습니다.

### 4.2 인프라 서비스 구성 (infra-compose.yml)

`docker/infra-compose.yml` 파일은 애플리케이션이 필요로 하는 핵심 인프라 서비스들을 정의합니다.

#### MySQL 서비스 상세 설명

MySQL은 관계형 데이터베이스입니다. 이 프로젝트는 MySQL 8.0 버전을 사용합니다. 왜 8.0일까요? MySQL 8.0은 성능 개선(특히 인덱스 성능), 더 나은 JSON 지원, Window Functions 같은 현대적인 SQL 기능을 제공합니다.

`ports: - "3306:3306"`는 호스트의 3306 포트를 컨테이너의 3306 포트에 매핑합니다. 이는 애플리케이션이 `localhost:3306`으로 MySQL에 접속할 수 있게 합니다.

환경변수들을 살펴보겠습니다. `MYSQL_ROOT_PASSWORD=root`는 root 사용자의 비밀번호를 설정합니다. 프로덕션에서는 절대 이렇게 간단한 비밀번호를 사용하면 안 되지만, 로컬 개발 환경에서는 편의를 위해 간단하게 설정합니다.

`MYSQL_USER=application`과 `MYSQL_PASSWORD=application`은 애플리케이션이 사용할 사용자를 생성합니다. root 사용자를 사용할 수도 있지만, 보안을 위해 제한된 권한을 가진 별도의 사용자를 만드는 것이 좋습니다.

`MYSQL_DATABASE=loopers`는 초기 데이터베이스를 생성합니다. 컨테이너가 시작되면 자동으로 "loopers"라는 이름의 데이터베이스가 만들어집니다.

`MYSQL_CHARACTER_SET=utf8mb4`와 `MYSQL_COLLATE=utf8mb4_general_ci`는 문자 인코딩을 설정합니다. utf8mb4는 이모지를 포함한 모든 유니코드 문자를 저장할 수 있습니다. 기존의 utf8은 실제로는 3바이트까지만 지원하여 이모지(4바이트 문자)를 저장할 수 없었습니다.

`volumes: - mysql-8-data:/var/lib/mysql`은 데이터를 영속화합니다. Docker 컨테이너는 기본적으로 ephemeral(일시적)합니다 - 컨테이너를 삭제하면 모든 데이터가 사라집니다. Volume을 사용하면 컨테이너를 삭제해도 데이터는 보존됩니다.

#### Redis Master 서비스 상세 설명

Redis는 인메모리 데이터 저장소로, 주로 캐시로 사용됩니다. 데이터베이스 쿼리는 느릴 수 있지만, Redis는 메모리에 데이터를 저장하므로 매우 빠릅니다.

`command` 섹션의 옵션들을 살펴보겠습니다. `--appendonly yes`는 AOF(Append-Only File) 영속성을 활성화합니다. Redis는 인메모리 저장소이므로 서버가 재시작되면 데이터가 사라질 수 있습니다. AOF는 모든 쓰기 명령을 디스크에 로깅하여, 재시작 시 이를 재실행하여 데이터를 복구할 수 있게 합니다.

`--save ""`는 RDB 스냅샷을 비활성화합니다. Redis는 두 가지 영속성 메커니즘을 가지고 있습니다 - AOF와 RDB입니다. RDB는 주기적으로 메모리의 스냅샷을 디스크에 저장합니다. 이 프로젝트는 AOF만 사용하여 설정을 단순화합니다.

`--latency-monitor-threshold 100`은 100ms 이상 걸리는 명령어를 모니터링합니다. Redis는 단일 스레드로 동작하므로, 하나의 느린 명령어가 전체 성능에 영향을 줄 수 있습니다. 이 옵션은 느린 명령어를 추적하여 성능 문제를 진단할 수 있게 합니다.

`healthcheck` 섹션은 컨테이너가 정상적으로 작동하는지 확인합니다. 5초마다 `redis-cli PING` 명령을 실행하여, PONG 응답을 받으면 정상으로 판단합니다. 만약 10회 연속 실패하면 컨테이너를 비정상으로 간주합니다. 이는 다른 서비스가 Redis가 준비될 때까지 기다릴 수 있게 합니다.

#### Redis Readonly (Replica) 서비스 상세 설명

Redis Replica는 Master의 복제본입니다. 모든 쓰기는 Master에 이루어지고, Replica는 이를 자동으로 복사합니다.

`depends_on: redis-master: condition: service_healthy`는 매우 중요합니다. 이는 Master가 정상 상태(healthcheck 통과)가 된 후에만 Replica를 시작하라는 의미입니다. Master가 준비되기 전에 Replica가 시작되면 복제 설정이 실패할 수 있습니다.

`--replicaof redis-master 6379`는 이 Redis 인스턴스가 redis-master의 6379 포트에 연결하여 데이터를 복제하라는 설정입니다. Docker Compose는 자동으로 서비스 이름(redis-master)을 DNS 이름으로 해석합니다.

`--replica-read-only yes`는 Replica를 읽기 전용으로 설정합니다. 실수로 Replica에 쓰기를 시도하면 에러가 발생하여, 데이터 불일치를 방지합니다.

`--appendfsync everysec`는 AOF 동기화 정책입니다. everysec는 1초마다 디스크에 동기화합니다. 이는 성능과 안전성 사이의 균형입니다. always로 설정하면 모든 쓰기마다 디스크에 동기화하여 더 안전하지만 느리고, no로 설정하면 운영체제에 맡겨서 빠르지만 데이터 손실 위험이 있습니다.

왜 Master-Replica 구조를 사용할까요? 읽기 부하를 분산할 수 있기 때문입니다. 대부분의 애플리케이션은 읽기가 쓰기보다 훨씬 많습니다. 읽기를 Replica로 분산하면 Master의 부하를 줄일 수 있습니다. 또한 Master에 장애가 발생하면 Replica를 승격시켜 서비스를 계속할 수 있습니다.

#### Kafka 서비스 상세 설명

Kafka는 분산 이벤트 스트리밍 플랫폼입니다. 이벤트란 "주문이 생성되었다", "재고가 업데이트되었다" 같은 일어난 일을 의미합니다. Kafka는 이러한 이벤트를 저장하고 전달합니다.

이 프로젝트는 Kafka 3.5.1을 사용하며, 중요한 점은 KRaft 모드로 실행된다는 것입니다. 과거 Kafka는 Zookeeper라는 별도의 코디네이션 서비스가 필요했지만, KRaft 모드는 Kafka만으로 클러스터를 관리할 수 있게 합니다.

`KAFKA_CFG_NODE_ID=1`은 이 브로커의 고유 ID입니다. 클러스터에 여러 브로커가 있다면 각각 다른 ID를 가집니다.

`KAFKA_CFG_PROCESS_ROLES=broker,controller`는 이 노드가 브로커(메시지 저장/전달)와 컨트롤러(클러스터 관리) 역할을 모두 수행한다는 의미입니다. 프로덕션에서는 이를 분리하지만, 로컬 개발에서는 하나의 노드가 모든 역할을 합니다.

`KAFKA_CFG_LISTENERS`와 `KAFKA_CFG_ADVERTISED_LISTENERS`는 복잡하지만 중요합니다. Kafka는 여러 리스너를 가질 수 있는데, 각각 다른 용도로 사용됩니다:
- `PLAINTEXT://:9092`는 Docker 네트워크 내부 통신용입니다. 다른 컨테이너가 `kafka:9092`로 연결할 수 있습니다.
- `PLAINTEXT_HOST://:19092`는 호스트에서의 접속용입니다. 개발자의 로컬 애플리케이션이 `localhost:19092`로 연결할 수 있습니다.
- `CONTROLLER://:9093`은 KRaft 컨트롤러 통신용입니다.

`KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1` 같은 설정들은 모두 1로 되어 있습니다. 복제 계수는 데이터를 몇 개의 브로커에 복사할지를 의미합니다. 프로덕션에서는 3 이상으로 설정하여 브로커 장애에 대비하지만, 로컬 개발에서는 브로커가 하나뿐이므로 1로 설정합니다.

`healthcheck`는 `kafka-topics.sh --bootstrap-server localhost:9092 --list` 명령을 실행합니다. 이 명령이 성공하면 Kafka가 정상적으로 작동하는 것입니다.

#### Kafka UI 서비스

Kafka UI는 웹 기반 관리 도구입니다. 커맨드라인으로 Kafka를 관리할 수도 있지만, GUI는 훨씬 직관적입니다. 브라우저에서 `localhost:9099`에 접속하면 토픽 목록, 메시지 내용, 컨슈머 그룹 상태 등을 볼 수 있습니다.

`depends_on: kafka: condition: service_healthy`는 Kafka가 준비된 후에만 UI를 시작합니다. Kafka가 준비되지 않은 상태에서 UI가 연결을 시도하면 실패하기 때문입니다.

### 4.3 모니터링 스택 (monitoring-compose.yml)

`docker/monitoring-compose.yml` 파일은 별도로 관리됩니다. 왜 infra-compose.yml과 분리했을까요? 모니터링은 선택적이기 때문입니다. 빠르게 개발하고 테스트할 때는 모니터링이 필요 없을 수 있습니다. 하지만 성능 문제를 진단하거나 프로덕션 환경을 시뮬레이션할 때는 모니터링이 필요합니다.

#### Prometheus 상세 설명

Prometheus는 시계열 데이터베이스입니다. 메트릭(숫자 데이터)를 시간에 따라 수집하고 저장합니다. 예를 들어, "지금 사용 중인 메모리는 얼마인가", "지난 1시간 동안 API 호출이 몇 번 있었는가" 같은 질문에 답할 수 있습니다.

`volumes: - ./grafana/prometheus.yml:/etc/prometheus/prometheus.yml`은 설정 파일을 마운트합니다. `prometheus.yml` 파일을 보면:

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'spring-boot-app'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['host.docker.internal:8080']
```

`scrape_interval: 15s`는 15초마다 메트릭을 수집하라는 의미입니다. 더 자주 수집하면 더 정밀한 데이터를 얻을 수 있지만, 저장 공간과 처리 부하가 증가합니다.

`job_name`은 수집 작업의 이름입니다. `metrics_path`는 메트릭을 어디서 가져올지 지정합니다. Spring Boot Actuator는 `/actuator/prometheus` 엔드포인트에 Prometheus 형식의 메트릭을 노출합니다.

`targets: ['host.docker.internal:8080']`는 매우 중요합니다. `host.docker.internal`은 Docker 컨테이너에서 호스트 머신을 가리키는 특수한 DNS 이름입니다. Spring Boot 애플리케이션은 컨테이너가 아니라 호스트에서 실행되므로, 이 주소를 사용해야 합니다.

#### Grafana 상세 설명

Grafana는 시각화 도구입니다. Prometheus가 수집한 데이터를 그래프와 차트로 표시합니다. `localhost:3000`에 접속하면 대시보드를 볼 수 있습니다.

`volumes: - ./grafana/provisioning:/etc/grafana/provisioning`은 자동 설정을 가능하게 합니다. Provisioning은 Grafana가 시작될 때 자동으로 데이터 소스, 대시보드 등을 설정하는 기능입니다.

`datasource.yml` 파일을 보면:

```yaml
apiVersion: 1
datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
```

이 설정은 Grafana가 자동으로 Prometheus를 데이터 소스로 추가하게 합니다. 수동으로 UI에서 설정하지 않아도 됩니다. `url: http://prometheus:9090`에서 `prometheus`는 Docker Compose의 서비스 이름입니다.

### 4.4 왜 이렇게 많은 인프라가 필요한가

초보자는 "왜 단순히 데이터베이스 하나만으로는 안 되나요?"라고 물을 수 있습니다. 각 컴포넌트는 특정 목적을 위해 최적화되어 있기 때문입니다.

**MySQL**은 관계형 데이터를 저장합니다. ACID 트랜잭션을 보장하여, 돈이나 재고 같은 중요한 데이터를 안전하게 관리합니다. 하지만 모든 쿼리가 디스크를 거치므로 느릴 수 있습니다.

**Redis**는 빠른 읽기가 필요한 경우에 사용합니다. 예를 들어, 상품 상세 정보는 자주 조회되지만 거의 변경되지 않습니다. 이를 Redis에 캐시하면 데이터베이스 부하를 크게 줄일 수 있습니다. 또한 세션 저장, Rate Limiting 같은 용도로도 사용됩니다.

**Kafka**는 비동기 처리와 이벤트 기반 아키텍처를 가능하게 합니다. 예를 들어, 주문이 생성되면 재고 시스템, 배송 시스템, 알림 시스템이 모두 이를 알아야 합니다. Kafka 없이는 주문 서비스가 모든 시스템을 직접 호출해야 하지만, Kafka를 사용하면 주문 서비스는 이벤트만 발행하고 관심 있는 시스템이 각자 구독합니다. 이는 시스템 간 결합도를 낮춥니다.

---

## 5. 코드 구조와 패턴 상세히 이해하기

### 5.1 도메인 모델의 설계 원칙

`ExampleModel` 클래스는 단순해 보이지만, 많은 설계 원칙을 담고 있습니다.

첫째, 생성자에서 검증합니다. `init` 블록은 생성자가 실행된 직후에 실행됩니다. 이름이나 설명이 비어있으면 예외를 던져서 객체 생성을 막습니다. 이는 "항상 유효한 상태만 유지한다"는 원칙입니다. 유효하지 않은 상태의 객체가 존재하면, 나중에 사용할 때 예외가 발생할 수 있고, 이를 추적하기 어렵습니다. 생성 시점에 막으면 문제의 원인을 즉시 알 수 있습니다.

둘째, 필드를 `protected set`으로 선언합니다. Kotlin의 프로퍼티는 getter와 setter를 자동으로 생성하는데, `protected set`은 setter를 protected로 만듭니다. 즉, 클래스 외부에서는 읽을 수만 있고 쓸 수는 없습니다. 왜 이렇게 할까요? 무분별한 수정을 방지하기 위해서입니다. 만약 `name`을 public setter로 노출하면, 누구든 `model.name = ""`처럼 빈 이름을 설정할 수 있습니다. 하지만 `update` 메서드를 통해서만 수정할 수 있게 하면, 검증 로직을 거치게 됩니다.

셋째, `BaseEntity`를 상속합니다. `BaseEntity`는 `modules/jpa`에 정의되어 있으며, 모든 엔티티가 공통으로 가져야 하는 필드를 제공합니다. `id`는 자동 증가하는 기본 키이고, `createdAt`과 `updatedAt`은 JPA의 `@PrePersist`와 `@PreUpdate` 콜백을 통해 자동으로 설정됩니다. `deletedAt`은 Soft Delete 패턴을 구현합니다. Soft Delete란 실제로 레코드를 삭제하지 않고, `deletedAt`에 삭제 시각을 기록하는 방식입니다. 이렇게 하면 실수로 삭제한 데이터를 복구할 수 있고, 데이터 분석에도 유용합니다.

### 5.2 리포지토리 패턴의 중요성

리포지토리 패턴은 데이터 접근 로직을 추상화합니다. `ExampleRepository` 인터페이스를 보면 매우 간단합니다:

```kotlin
interface ExampleRepository {
    fun find(id: Long): ExampleModel?
    fun save(model: ExampleModel): ExampleModel
}
```

이 인터페이스는 도메인 계층에 있지만, JPA, MyBatis, 또는 외부 API 같은 구현 세부사항을 전혀 언급하지 않습니다. 도메인 서비스는 단지 "id로 예시를 찾아라"라고 요청할 뿐, 그것이 어떻게 구현되는지 모릅니다.

`ExampleRepositoryImpl`은 infrastructure 계층에서 이 인터페이스를 구현합니다:

```kotlin
@Component
class ExampleRepositoryImpl(
    private val exampleJpaRepository: ExampleJpaRepository,
) : ExampleRepository {
    override fun find(id: Long): ExampleModel? {
        return exampleJpaRepository.findByIdOrNull(id)
    }
}
```

`ExampleJpaRepository`는 Spring Data JPA의 `JpaRepository`를 상속합니다. Spring Data JPA는 마법같은 기능을 제공합니다 - 인터페이스만 정의하면 구현체를 자동으로 생성해줍니다. `findByIdOrNull`은 Spring Data의 확장 함수로, Optional 대신 nullable 타입을 반환하여 Kotlin 친화적입니다.

이러한 분리의 이점은 무엇일까요? 첫째, 테스트가 쉬워집니다. 도메인 서비스를 테스트할 때 실제 데이터베이스 없이도 리포지토리를 Mock으로 대체할 수 있습니다. 둘째, 기술을 교체하기 쉽습니다. JPA에서 MongoDB로 변경하려면 `ExampleRepositoryImpl`만 새로 작성하면 됩니다. 셋째, 도메인 로직이 인프라에 오염되지 않습니다.

### 5.3 서비스와 파사드의 차이

초보자는 종종 서비스와 파사드의 차이를 혼란스러워합니다. 간단히 말하면, 서비스는 도메인 로직을 처리하고, 파사드는 여러 서비스를 조율합니다.

`ExampleService`를 보면:

```kotlin
@Component
class ExampleService(
    private val exampleRepository: ExampleRepository,
) {
    @Transactional(readOnly = true)
    fun getExample(id: Long): ExampleModel {
        return exampleRepository.find(id)
            ?: throw CoreException(errorType = ErrorType.NOT_FOUND, customMessage = "[id = $id] 예시를 찾을 수 없습니다.")
    }
}
```

이 서비스는 단일 도메인(Example)에 집중합니다. "예시를 찾고, 없으면 예외를 던진다"는 비즈니스 규칙을 구현합니다. `@Transactional(readOnly = true)`는 이 메서드가 데이터를 변경하지 않음을 명시합니다. 읽기 전용 트랜잭션은 flush를 하지 않아 성능이 더 좋고, 실수로 데이터를 변경하는 것을 방지합니다.

`ExampleFacade`는 다릅니다:

```kotlin
@Component
class ExampleFacade(
    private val exampleService: ExampleService,
) {
    fun getExample(id: Long): ExampleInfo {
        return exampleService.getExample(id)
            .let { ExampleInfo.from(it) }
    }
}
```

이 간단한 예제에서는 하나의 서비스만 호출하지만, 실제 애플리케이션에서는 여러 서비스를 조율할 수 있습니다. 예를 들어, "사용자 정보 조회" 파사드는 사용자 서비스, 포인트 서비스, 주문 이력 서비스를 모두 호출하여 종합 정보를 제공할 수 있습니다.

또한 파사드는 도메인 모델을 DTO로 변환합니다. `ExampleInfo`는 순수한 데이터 클래스로, JPA 관련 메타데이터가 없습니다. 이는 지연 로딩 문제나 순환 참조를 방지합니다.

### 5.4 컨트롤러와 DTO의 역할

`ExampleV1Controller`는 HTTP와 비즈니스 로직 사이의 다리입니다:

```kotlin
@RestController
@RequestMapping("/api/v1/examples")
class ExampleV1Controller(
    private val exampleFacade: ExampleFacade,
) : ExampleV1ApiSpec {
    @GetMapping("/{exampleId}")
    override fun getExample(
        @PathVariable(value = "exampleId") exampleId: Long,
    ): ApiResponse<ExampleV1Dto.ExampleResponse> {
        return exampleFacade.getExample(exampleId)
            .let { ExampleV1Dto.ExampleResponse.from(it) }
            .let { ApiResponse.success(it) }
    }
}
```

컨트롤러는 세 가지 일을 합니다. 첫째, HTTP 요청을 파싱합니다. `@PathVariable`은 URL의 `{exampleId}` 부분을 Long 타입으로 변환합니다. 둘째, 파사드를 호출합니다. 셋째, 결과를 HTTP 응답으로 변환합니다.

`ExampleV1ApiSpec` 인터페이스를 구현하는 이유는 무엇일까요? API 명세를 코드와 분리하기 위해서입니다. 이 인터페이스에는 Swagger 애노테이션이 포함되어 있어, API 문서를 자동으로 생성합니다. 컨트롤러는 단지 이 명세를 구현할 뿐입니다.

`ApiResponse`는 표준 응답 포맷입니다:

```kotlin
data class ApiResponse<T>(
    val success: Boolean,
    val data: T?,
    val error: ErrorInfo?,
)
```

모든 API 응답이 이 구조를 따르면, 클라이언트는 일관된 방식으로 응답을 처리할 수 있습니다. 성공 시 `success: true`와 `data`를 받고, 실패 시 `success: false`와 `error`를 받습니다.

### 5.5 예외 처리 전략

`@RestControllerAdvice`는 전역 예외 처리기입니다:

```kotlin
@RestControllerAdvice
class ApiControllerAdvice {
    @ExceptionHandler(CoreException::class)
    fun handleCoreException(e: CoreException): ResponseEntity<ApiResponse<Nothing>> {
        return ResponseEntity
            .status(e.errorType.httpStatus)
            .body(ApiResponse.error(e.errorType.code, e.message ?: e.errorType.message))
    }
}
```

도메인 계층이나 애플리케이션 계층에서 `CoreException`을 던지면, 이 핸들러가 자동으로 캐치합니다. 핸들러는 예외를 적절한 HTTP 응답으로 변환합니다. 예를 들어, `ErrorType.NOT_FOUND`는 404 상태 코드를, `ErrorType.BAD_REQUEST`는 400을 반환합니다.

이렇게 하면 모든 컨트롤러에서 try-catch를 반복할 필요가 없습니다. 비즈니스 로직은 단지 예외를 던지기만 하면 되고, 프레임워크가 이를 적절히 처리합니다.

---

## 6. 테스트 전략 완전히 이해하기

### 6.1 왜 Testcontainers를 사용하는가

많은 프로젝트가 테스트에 H2 같은 인메모리 데이터베이스를 사용합니다. 빠르고 설정이 간단하기 때문입니다. 하지만 문제가 있습니다 - H2는 MySQL이 아닙니다. SQL 방언이 다르고, 지원하는 기능이 다릅니다. H2에서 통과한 테스트가 실제 MySQL에서 실패할 수 있습니다.

Testcontainers는 이 문제를 해결합니다. Docker 컨테이너를 사용하여 실제 MySQL을 테스트 환경에서 실행합니다. 테스트는 느려질 수 있지만, 프로덕션 환경과 동일한 데이터베이스에서 테스트하므로 신뢰도가 높습니다.

`MySqlTestContainersConfig`를 보면:

```kotlin
@TestConfiguration
class MySqlTestContainersConfig {
    companion object {
        private val mysqlContainer = MySQLContainer<Nothing>("mysql:8.0").apply {
            withDatabaseName("test")
            withUsername("test")
            withPassword("test")
            start()
        }
    }

    @Bean
    @Primary
    fun testDataSource(): DataSource {
        return HikariDataSource().apply {
            jdbcUrl = mysqlContainer.jdbcUrl
            username = mysqlContainer.username
            password = mysqlContainer.password
        }
    }
}
```

`companion object`의 `mysqlContainer`는 클래스 로딩 시 한 번만 생성됩니다. 즉, 모든 테스트가 동일한 MySQL 컨테이너를 공유합니다. 각 테스트마다 컨테이너를 새로 띄우면 너무 느리기 때문입니다.

`@Primary`가 붙은 `testDataSource` 빈은 기존의 DataSource를 대체합니다. Spring은 여러 DataSource 빈이 있을 때 `@Primary`가 붙은 것을 우선 사용합니다. 이렇게 하면 테스트 설정 파일(`application.yml`의 test 프로파일)을 수정하지 않아도 Testcontainers를 사용할 수 있습니다.

### 6.2 DatabaseCleanUp의 동작 원리

테스트 간 격리는 매우 중요합니다. 한 테스트가 데이터베이스에 데이터를 남기면, 다음 테스트가 영향을 받을 수 있습니다. `DatabaseCleanUp`은 모든 테이블의 데이터를 삭제하여 깨끗한 상태를 만듭니다:

```kotlin
@Component
class DatabaseCleanUp(
    private val entityManager: EntityManager,
) {
    @Transactional
    fun truncateAllTables() {
        val tables = entityManager.metamodel.entities
            .map { it.name }

        entityManager.createNativeQuery("SET FOREIGN_KEY_CHECKS = 0").executeUpdate()
        tables.forEach { table ->
            entityManager.createNativeQuery("TRUNCATE TABLE $table").executeUpdate()
        }
        entityManager.createNativeQuery("SET FOREIGN_KEY_CHECKS = 1").executeUpdate()
    }
}
```

`entityManager.metamodel.entities`는 JPA가 관리하는 모든 엔티티를 가져옵니다. 각 엔티티는 하나의 테이블에 매핑되므로, 이를 통해 모든 테이블 이름을 알 수 있습니다.

`TRUNCATE TABLE`은 테이블의 모든 데이터를 삭제합니다. `DELETE`와 다른 점은 더 빠르고, 자동 증가 카운터도 리셋한다는 것입니다.

`SET FOREIGN_KEY_CHECKS = 0`과 `= 1`은 외래 키 제약을 일시적으로 비활성화합니다. 외래 키가 있으면 테이블을 특정 순서로 삭제해야 하는데, 이는 복잡합니다. 제약을 끄면 순서에 상관없이 삭제할 수 있습니다.

### 6.3 E2E 테스트의 구조

`ExampleV1ApiE2ETest`는 전체 스택을 테스트합니다:

```kotlin
@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
class ExampleV1ApiE2ETest @Autowired constructor(
    private val testRestTemplate: TestRestTemplate,
    private val exampleJpaRepository: ExampleJpaRepository,
    private val databaseCleanUp: DatabaseCleanUp,
) {
    @AfterEach
    fun tearDown() {
        databaseCleanUp.truncateAllTables()
    }

    @Test
    fun returnsExampleInfo_whenValidIdIsProvided() {
        // arrange
        val exampleModel = exampleJpaRepository.save(ExampleModel(name = "예시 제목", description = "예시 설명"))
        val requestUrl = "/api/v1/examples/${exampleModel.id}"

        // act
        val responseType = object : ParameterizedTypeReference<ApiResponse<ExampleV1Dto.ExampleResponse>>() {}
        val response = testRestTemplate.exchange(requestUrl, HttpMethod.GET, HttpEntity<Any>(Unit), responseType)

        // assert
        assertAll(
            { assertThat(response.statusCode.is2xxSuccessful).isTrue() },
            { assertThat(response.body?.data?.id).isEqualTo(exampleModel.id) },
            { assertThat(response.body?.data?.name).isEqualTo(exampleModel.name) },
        )
    }
}
```

`@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)`는 실제 웹 서버를 랜덤 포트로 시작합니다. 왜 랜덤일까요? 여러 테스트를 병렬로 실행할 때 포트 충돌을 방지하기 위해서입니다.

테스트는 3A 패턴을 따릅니다:
1. **Arrange(준비)**: 테스트 데이터를 생성합니다. `exampleJpaRepository.save`를 사용하여 데이터베이스에 예시를 저장합니다.
2. **Act(실행)**: 실제 동작을 수행합니다. `testRestTemplate.exchange`로 HTTP GET 요청을 보냅니다.
3. **Assert(검증)**: 결과를 확인합니다. 응답 상태 코드가 2xx인지, 반환된 데이터가 저장한 데이터와 일치하는지 확인합니다.

`@AfterEach`의 `tearDown`은 각 테스트 후 데이터베이스를 정리합니다. 이는 테스트 격리를 보장합니다.

이러한 E2E 테스트는 컨트롤러, 파사드, 서비스, 리포지토리, 데이터베이스까지 모든 레이어를 검증합니다. 단위 테스트보다 느리지만, 전체 시스템이 올바르게 통합되었는지 확인할 수 있습니다.

---

## 7. 프로젝트를 처음부터 재구축하는 방법

이제 이 프로젝트의 모든 측면을 이해했으니, 처음부터 재구축하는 과정을 간략히 설명하겠습니다.

### 7.1 개발 환경 준비

먼저 JDK 21, Docker, Git을 설치합니다. IDE는 IntelliJ IDEA를 권장합니다 - Kotlin 지원이 가장 뛰어납니다.

### 7.2 프로젝트 초기화

빈 디렉토리를 만들고 Git을 초기화합니다. Gradle Wrapper를 설정하여 모든 개발자가 동일한 Gradle 버전을 사용하게 합니다.

### 7.3 빌드 스크립트 작성

`settings.gradle.kts`에서 프로젝트 이름과 모듈 구조를 정의합니다. `gradle.properties`에 모든 버전 정보를 중앙화합니다. 루트 `build.gradle.kts`에서 공통 설정을 정의합니다.

### 7.4 모듈 생성

`apps`, `modules`, `supports` 디렉토리를 만들고, 각 모듈의 디렉토리 구조를 생성합니다. 각 모듈의 `build.gradle.kts`에서 필요한 의존성을 선언합니다.

### 7.5 인프라 설정

`docker/infra-compose.yml`에서 MySQL, Redis, Kafka를 정의합니다. 각 서비스의 포트, 환경변수, 볼륨을 적절히 설정합니다.

### 7.6 공통 컴포넌트 구현

`modules/jpa`의 `BaseEntity`, `DataSourceConfig`, `QueryDslConfig`를 작성합니다. `modules/redis`의 `RedisConfig`를 작성합니다. `modules/kafka`의 `KafkaConfig`를 작성합니다.

### 7.7 애플리케이션 구현

`apps/commerce-api`에서 계층별로 코드를 작성합니다. 도메인 모델부터 시작하여, 리포지토리, 서비스, 파사드, 컨트롤러 순서로 구현합니다.

### 7.8 테스트 작성

각 계층에 대한 테스트를 작성합니다. 단위 테스트로 도메인 로직을 검증하고, E2E 테스트로 전체 흐름을 검증합니다.

### 7.9 코드 품질 설정

ktlint를 설정하고, Git Pre-commit Hook을 추가하여 커밋 전 자동으로 코드 스타일을 검사합니다.

### 7.10 문서화

README, API 문서, 아키텍처 다이어그램을 작성합니다. 새로운 팀원이 쉽게 온보딩할 수 있도록 충분한 문서를 제공합니다.

---

## 결론

이 프로젝트는 단순한 템플릿이 아니라, 엔터프라이즈 애플리케이션을 위한 견고한 기반입니다. 3-Tier 모듈 구조는 코드를 명확하게 조직하고, Layered Architecture는 각 계층의 책임을 분리하며, 완벽한 인프라 통합은 프로덕션 준비 상태를 보장합니다.

이 문서를 통해 프로젝트의 모든 파일, 설정, 패턴을 이해했을 것입니다. 이제 이 템플릿을 기반으로 자신만의 애플리케이션을 구축하거나, 필요에 따라 커스터마이징할 수 있습니다. 중요한 것은 각 결정의 이유를 이해하는 것입니다 - 그래야 변경할 때 어떤 영향이 있을지 판단할 수 있습니다.
